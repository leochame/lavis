import { useState, useEffect, useRef, useCallback } from 'react';
import { agentApi } from '../api/agentApi';
import { useVoiceRecorder } from './useVoiceRecorder';
import { useWakeWord } from './useWakeWord';

/**
 * è¯­éŸ³äº¤äº’çŠ¶æ€
 */
export type VoiceState = 'idle' | 'listening' | 'processing' | 'speaking' | 'error';

/**
 * å…¨å±€è¯­éŸ³ Hook è¿”å›å€¼
 */
export interface UseGlobalVoiceReturn {
  /** å½“å‰è¯­éŸ³çŠ¶æ€ */
  voiceState: VoiceState;
  /** å”¤é†’è¯æ˜¯å¦æ­£åœ¨ç›‘å¬ */
  isWakeWordListening: boolean;
  /** æ˜¯å¦æ­£åœ¨å½•éŸ³ */
  isRecording: boolean;
  /** å½•éŸ³æœºæ˜¯å¦å·²å‡†å¤‡å¥½ï¼ˆé¿å…å”¤é†’è¯æ£€æµ‹åç«‹å³è¯´è¯è¢«æˆªæ–­ï¼‰ */
  isRecorderReady: boolean;
  /** ç”¨æˆ·è¯­éŸ³è½¬æ–‡å­—ç»“æœ */
  transcribedText: string;
  /** Agent å›å¤æ–‡æœ¬ */
  agentResponse: string;
  /** Agent å›å¤éŸ³é¢‘ (Base64) */
  agentAudio: string | null;
  /** é”™è¯¯ä¿¡æ¯ */
  error: string | null;
  /** å”¤é†’è¯æ˜¯å¦è¢«æ£€æµ‹åˆ°ï¼ˆç”¨äºåˆ‡æ¢åˆ°èŠå¤©æ¨¡å¼ï¼‰ */
  wakeWordDetected: boolean;
  /** æ‰‹åŠ¨å¼€å§‹å½•éŸ³ */
  startRecording: () => void;
  /** æ‰‹åŠ¨åœæ­¢å½•éŸ³ */
  stopRecording: () => void;
  /** é‡ç½®çŠ¶æ€ */
  reset: () => void;
}

/**
 * å…¨å±€ AudioContext å•ä¾‹
 * åœ¨ç”¨æˆ·ç‚¹å‡»å¼€å§‹æ—¶åˆ›å»ºï¼Œå¤ç”¨ç”¨äºæ‰€æœ‰éŸ³é¢‘æ’­æ”¾
 * é¿å…é‡å¤åˆ›å»ºå¯¼è‡´çš„æµè§ˆå™¨é™åˆ¶é—®é¢˜
 */
let globalAudioContext: AudioContext | null = null;

/**
 * è·å–æˆ–åˆ›å»ºå…¨å±€ AudioContext
 * å¿…é¡»åœ¨ç”¨æˆ·æ‰‹åŠ¿è§¦å‘åè°ƒç”¨
 */
const getAudioContext = (): AudioContext | null => {
  if (!globalAudioContext) {
    try {
      const AudioContextClass = window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext;
      globalAudioContext = new AudioContextClass();
      console.log('âœ… Global AudioContext created');
    } catch (e) {
      console.warn("AudioContext not supported or failed", e);
    }
  }
  return globalAudioContext;
};

/**
 * ç®€å•çš„ "Ding" æç¤ºéŸ³ç”Ÿæˆå™¨
 * ä½¿ç”¨å…¨å±€ AudioContext åˆæˆä¸€ä¸ªæ¸…è„†çš„æç¤ºéŸ³
 */
const playDing = () => {
  try {
    const audioContext = getAudioContext();
    if (!audioContext) return;

    // å¦‚æœ AudioContext å¤„äº suspended çŠ¶æ€ï¼Œå°è¯• resume
    if (audioContext.state === 'suspended') {
      audioContext.resume().catch(console.warn);
    }

    const oscillator = audioContext.createOscillator();
    const gainNode = audioContext.createGain();

    oscillator.connect(gainNode);
    gainNode.connect(audioContext.destination);

    // ä¸¤ä¸ªéŸ³è°ƒå åŠ ï¼Œæ›´æ‚¦è€³
    oscillator.type = 'sine';
    oscillator.frequency.setValueAtTime(880, audioContext.currentTime); // A5
    oscillator.frequency.exponentialRampToValueAtTime(1320, audioContext.currentTime + 0.08); // E6
    oscillator.frequency.exponentialRampToValueAtTime(1760, audioContext.currentTime + 0.15); // A6

    gainNode.gain.setValueAtTime(0.3, audioContext.currentTime);
    gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + 0.2);

    oscillator.start();
    oscillator.stop(audioContext.currentTime + 0.2);
  } catch (e) {
    console.warn("Ding sound playback failed", e);
  }
};

/**
 * å…¨å±€è¯­éŸ³äº¤äº’ Hook
 *
 * æ ¸å¿ƒåŠŸèƒ½:
 * 1. å”¤é†’è¯ç›‘å¬ (å§‹ç»ˆè¿è¡Œï¼Œé™¤éæ­£åœ¨å¤„ç†å…¶ä»–è¯­éŸ³ä»»åŠ¡)
 * 2. è¯­éŸ³å½•åˆ¶
 * 3. è¯­éŸ³å¯¹è¯ (STT -> Agent -> TTS)
 * 4. çŠ¶æ€ç®¡ç†
 *
 * è®¾è®¡åŸåˆ™:
 * - è¿™ä¸ª Hook åº”è¯¥åœ¨ App.tsx ä¸­åˆå§‹åŒ–ï¼Œç¡®ä¿ç”Ÿå‘½å‘¨æœŸæœ€é•¿
 * - æ— è®º UI å¦‚ä½•åˆ‡æ¢ï¼Œå”¤é†’è¯ç›‘å¬å§‹ç»ˆå­˜åœ¨
 * - å¿…é¡»åœ¨ç”¨æˆ·ç‚¹å‡»å¼€å§‹åæ‰åˆå§‹åŒ–éŸ³é¢‘åŠŸèƒ½ï¼ˆæµè§ˆå™¨å®‰å…¨ç­–ç•¥ï¼‰
 *
 * @param isAppStarted - ç”¨æˆ·æ˜¯å¦å·²ç‚¹å‡»"å¼€å§‹"æŒ‰é’®ï¼ˆæ¿€æ´»éº¦å…‹é£å’ŒéŸ³é¢‘ä¸Šä¸‹æ–‡ï¼‰
 */
export function useGlobalVoice(isAppStarted: boolean): UseGlobalVoiceReturn {
  // æ ¸å¿ƒçŠ¶æ€
  const [voiceState, setVoiceState] = useState<VoiceState>('idle');
  const [transcribedText, setTranscribedText] = useState('');
  const [agentResponse, setAgentResponse] = useState('');
  const [agentAudio, setAgentAudio] = useState<string | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [wakeWordDetected, setWakeWordDetected] = useState(false);
  const [isRecorderReady, setIsRecorderReady] = useState(false); // å½•éŸ³æœºæ˜¯å¦å·²å‡†å¤‡å¥½

  // éŸ³é¢‘æ’­æ”¾å™¨å¼•ç”¨
  const audioRef = useRef<HTMLAudioElement | null>(null);

  // åˆå§‹åŒ–å½•éŸ³ Hook
  const {
    isRecording,
    isRecordingReady,
    startRecording: recorderStart,
    stopRecording: recorderStop,
    audioBlob,
    error: recorderError,
    isTooShort,
  } = useVoiceRecorder();

  // è¿½è¸ªå½•éŸ³æœºæ˜¯å¦å·²å‡†å¤‡å¥½
  useEffect(() => {
    if (isRecordingReady) {
      setIsRecorderReady(true);
    }
  }, [isRecordingReady]);

  // æ›´æ–°çŠ¶æ€çš„ä¾¿æ·å‡½æ•°
  const updateState = useCallback((newState: VoiceState) => {
    console.log(`ğŸ¤ Voice state: ${voiceState} -> ${newState}`);
    setVoiceState(newState);
  }, [voiceState]);

  // å¤„ç†è¯­éŸ³å¯¹è¯
  const handleVoiceChat = useCallback(async (blob: Blob) => {
    updateState('processing');
    setError(null);
    
    try {
      const file = new File([blob], "recording.webm", { type: blob.type });
      console.log('ğŸ“¤ Uploading audio...', { size: blob.size, type: blob.type });
      
      const response = await agentApi.voiceChat(file);
      
      if (response.success) {
        setTranscribedText(response.user_text);
        setAgentResponse(response.agent_text);
        setAgentAudio(response.agent_audio);
        
        // å¦‚æœæœ‰éŸ³é¢‘ï¼Œæ’­æ”¾å®ƒ
        if (response.agent_audio) {
          updateState('speaking');
          playAgentAudio(response.agent_audio);
        } else {
          updateState('idle');
        }
        
        console.log('âœ… Voice chat completed', { 
          duration: response.duration_ms,
          userText: response.user_text?.slice(0, 50)
        });
      } else {
        throw new Error('Voice chat response indicated failure');
      }
    } catch (err) {
      console.error('Voice chat failed:', err);
      setError(err instanceof Error ? err.message : 'Unknown error');
      setAgentResponse('æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯­éŸ³è¯·æ±‚æ—¶å‡ºé”™äº†ã€‚');
      updateState('error');
      
      // 3ç§’åæ¢å¤ç©ºé—²çŠ¶æ€
      setTimeout(() => {
        setVoiceState(prev => prev === 'error' ? 'idle' : prev);
      }, 3000);
    }
  }, [updateState]);

  // æ’­æ”¾ Agent éŸ³é¢‘
  // æ”¯æŒ WAV (DashScope SDK) å’Œ MP3 (OpenAI compatible) æ ¼å¼
  const playAgentAudio = useCallback((base64Audio: string) => {
    if (!audioRef.current) {
      audioRef.current = new Audio();
    }
    
    const audio = audioRef.current;
    
    // æ£€æµ‹éŸ³é¢‘æ ¼å¼ (WAV æ–‡ä»¶ä»¥ "UklGR" å¼€å¤´ï¼ŒMP3 ä»¥ "//uQ" æˆ–å…¶ä»–å¼€å¤´)
    const isWav = base64Audio.startsWith('UklGR') || base64Audio.startsWith('Ukl');
    const mimeType = isWav ? 'audio/wav' : 'audio/mp3';
    
    audio.src = `data:${mimeType};base64,${base64Audio}`;
    console.log(`ğŸ”Š Playing audio (format: ${mimeType})`);
    
    audio.onended = () => {
      updateState('idle');
    };
    
    audio.onerror = () => {
      console.error('Audio playback failed');
      updateState('idle');
    };
    
    audio.play().catch(err => {
      console.error('Failed to play audio:', err);
      updateState('idle');
    });
  }, [updateState]);

  // å”¤é†’è¯å›è°ƒ - è§¦å‘å½•éŸ³
  const handleWakeWord = useCallback(() => {
    console.log("ğŸ‰ Wake word 'Hi Lavis' detected! Triggering recording...");
    if (voiceState === 'idle') {
      // è®¾ç½®å”¤é†’è¯æ£€æµ‹æ ‡å¿—ï¼ˆç”¨äº App åˆ‡æ¢åˆ°èŠå¤©æ¨¡å¼ï¼‰
      setWakeWordDetected(true);
      // å»¶è¿Ÿé‡ç½®æ ‡å¿—
      setTimeout(() => setWakeWordDetected(false), 500);

      playDing();
      setTranscribedText('');
      setAgentResponse('');
      setAgentAudio(null);
      setError(null);
      updateState('listening');
      recorderStart();
    }
  }, [voiceState, updateState, recorderStart]);

  // åˆå§‹åŒ–å”¤é†’è¯ Hook (å§‹ç»ˆç›‘å¬ï¼Œé™¤éæ­£åœ¨å¤„ç†è¯­éŸ³)
  // ä¼˜å…ˆä½¿ç”¨ publicPathï¼ˆæ¨èï¼‰ï¼Œå…¶æ¬¡ Base64
  // åªåœ¨åº”ç”¨å¯åŠ¨ä¸”ç©ºé—²æ—¶æ‰ç›‘å¬
  const { isListening: isWakeWordListening, error: wakeWordError } = useWakeWord({
    accessKey: import.meta.env.VITE_PICOVOICE_KEY,
    keywordPath: import.meta.env.VITE_WAKE_WORD_PATH || '/hi-lavis.ppn',
    keywordBase64: import.meta.env.VITE_WAKE_WORD_BASE64,
    onWake: handleWakeWord,
    enabled: isAppStarted && voiceState === 'idle' // åªæœ‰åœ¨åº”ç”¨å¯åŠ¨ä¸”ç©ºé—²æ—¶æ‰ç›‘å¬
  });

  // Debug: æ‰“å°ç¯å¢ƒå˜é‡çŠ¶æ€
  useEffect(() => {
    const picoKey = import.meta.env.VITE_PICOVOICE_KEY;
    const wakeWordPath = import.meta.env.VITE_WAKE_WORD_PATH || '/hi-lavis.ppn';
    const wakeWordB64 = import.meta.env.VITE_WAKE_WORD_BASE64;
    
    console.log('ğŸ”§ GlobalVoice: Environment variables check:');
    console.log(`   VITE_PICOVOICE_KEY: ${picoKey ? 'âœ… Set (' + picoKey.slice(0, 15) + '...)' : 'âŒ NOT SET'}`);
    console.log(`   VITE_WAKE_WORD_PATH: ${wakeWordPath} (default: /hi-lavis.ppn)`);
    console.log(`   VITE_WAKE_WORD_BASE64: ${wakeWordB64 ? 'âœ… Set (backup)' : 'âŒ NOT SET'}`);
  }, []);

  // ç›‘å¬å½•éŸ³å®Œæˆï¼Œè‡ªåŠ¨ä¸Šä¼ 
  useEffect(() => {
    if (audioBlob && voiceState === 'listening' && !isTooShort) {
      handleVoiceChat(audioBlob);
    } else if (isTooShort && voiceState === 'listening') {
      // å½•éŸ³è¿‡çŸ­æˆ–å…¨ç¨‹é™éŸ³ï¼Œç›´æ¥å›åˆ° idle çŠ¶æ€
      console.log('â­ï¸ Recording too short or full silence, skipping upload and returning to idle');
      updateState('idle');
    }
  }, [audioBlob, voiceState, isTooShort, handleVoiceChat, updateState]);

  // åŒæ­¥å½•éŸ³çŠ¶æ€
  useEffect(() => {
    if (isRecording && voiceState !== 'listening') {
      updateState('listening');
    }
  }, [isRecording, voiceState, updateState]);

  // åˆå¹¶é”™è¯¯ä¿¡æ¯
  useEffect(() => {
    if (wakeWordError && !error) {
      setError(wakeWordError);
    }
    if (recorderError && !error) {
      setError(recorderError);
    }
  }, [wakeWordError, recorderError, error]);

  // æ‰‹åŠ¨å¼€å§‹å½•éŸ³
  const startRecording = useCallback(() => {
    setTranscribedText('');
    setAgentResponse('');
    setAgentAudio(null);
    setError(null);
    
    playDing();
    updateState('listening');
    recorderStart();
  }, [updateState, recorderStart]);

  // æ‰‹åŠ¨åœæ­¢å½•éŸ³
  const stopRecording = useCallback(() => {
    recorderStop();
  }, [recorderStop]);

  // é‡ç½®çŠ¶æ€
  const reset = useCallback(() => {
    setVoiceState('idle');
    setTranscribedText('');
    setAgentResponse('');
    setAgentAudio(null);
    setError(null);
    
    // åœæ­¢éŸ³é¢‘æ’­æ”¾
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.src = '';
    }
  }, []);

  // æ¸…ç†
  useEffect(() => {
    return () => {
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.src = '';
      }
    };
  }, []);

  return {
    voiceState,
    isWakeWordListening,
    isRecording,
    isRecorderReady, // å½•éŸ³æœºå‡†å¤‡å¥½çŠ¶æ€
    transcribedText,
    agentResponse,
    agentAudio,
    error,
    wakeWordDetected,
    startRecording,
    stopRecording,
    reset,
  };
}

