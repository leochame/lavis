import { useState, useRef, useCallback } from 'react';

/**
 * Voice Recorder Hook
 *
 * ä½¿ç”¨ MediaRecorder API è¿›è¡Œå½•éŸ³ï¼Œæ”¯æŒæ™ºèƒ½é™éŸ³æ£€æµ‹ï¼ˆVADï¼‰
 *
 * æ ¸å¿ƒç®—æ³•ï¼š
 * 1. 5ç§’ä¿æŠ¤æœŸï¼šå½•éŸ³å¼€å§‹çš„å‰5ç§’å¼ºåˆ¶å½•éŸ³ï¼Œä¸åœæ­¢
 * 2. åŠ¨æ€é™éŸ³æˆªæ–­ï¼š5ç§’åå¦‚æœé™éŸ³è¶…è¿‡3ç§’åˆ™åœæ­¢å½•éŸ³
 * 3. æœ€å¤§å½•éŸ³æ—¶é•¿ï¼š60ç§’è‡ªåŠ¨åœæ­¢
 * 4. å…¨ç¨‹é™éŸ³æ£€æµ‹ï¼šä½èƒ½é‡éŸ³é¢‘è‡ªåŠ¨ä¸¢å¼ƒ
 */
export interface UseVoiceRecorderReturn {
  isRecording: boolean;
  isRecordingReady: boolean; // å½•éŸ³æœºæ˜¯å¦å·²å‡†å¤‡å¥½ï¼ˆè·å–åˆ°éº¦å…‹é£æµåï¼‰
  startRecording: () => void;
  stopRecording: () => void;
  audioBlob: Blob | null;
  audioDuration: number;
  error: string | null;
  isTooShort: boolean; // å½•éŸ³æ—¶é•¿æ˜¯å¦è¿‡çŸ­ï¼ˆ< 0.5ç§’ï¼‰
}

interface EnergyInfo {
  avgAudioEnergy: number;
  samplesCount: number;
}

type CleanupFunction = () => EnergyInfo | void;

export function useVoiceRecorder(): UseVoiceRecorderReturn {
  const [isRecording, setIsRecording] = useState(false);
  const [isRecordingReady, setIsRecordingReady] = useState(false);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [audioDuration, setAudioDuration] = useState(0);
  const [error, setError] = useState<string | null>(null);
  const [isTooShort, setIsTooShort] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const startTimeRef = useRef<number>(0);

  // é™éŸ³æ£€æµ‹
  const analyzeAudioLevel = useCallback((analyser: AnalyserNode) => {
    if (!mediaRecorderRef.current) return 0;

    const dataArray = new Float32Array(analyser.fftSize);
    analyser.getFloatFrequencyData(dataArray);

    // è®¡ç®—éŸ³é¢‘èƒ½é‡ï¼ˆRMSï¼‰
    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) {
      sum += dataArray[i] * dataArray[i];
    }
    const rms = Math.sqrt(sum / dataArray.length);
    return rms;
  }, []);

  // é‡Šæ”¾éº¦å…‹é£æµ
  const releaseStream = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log('ğŸ”‡ Audio track stopped');
      });
      streamRef.current = null;
    }
  }, []);

  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      const duration = (Date.now() - startTimeRef.current) / 1000;
      
      // å¼ºåˆ¶æœ€å°‘å½•éŸ³ 1 ç§’
      if (duration < 1.0) {
        console.log(`â³ Recording too short (${duration.toFixed(2)}s), waiting for minimum 1s...`);
        // å»¶è¿Ÿåœæ­¢ï¼Œç¡®ä¿è‡³å°‘ 1 ç§’
        const remainingTime = (1.0 - duration) * 1000;
        setTimeout(() => {
          if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
            mediaRecorderRef.current.stop();
            setIsRecording(false);
            releaseStream();
            console.log('Recording stopped (after minimum time)');
          }
        }, remainingTime);
        return;
      }
      
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      releaseStream();
      console.log(`Recording stopped (${duration.toFixed(2)}s)`);
    }
  }, [releaseStream]);

  const checkSilence = useCallback((): CleanupFunction => {
    if (!mediaRecorderRef.current) return () => ({ avgAudioEnergy: 0, samplesCount: 0 });

    const audioContext = new (window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext)();
    const source = audioContext.createMediaStreamSource(
      mediaRecorderRef.current.stream || new MediaStream()
    );
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 256;
    source.connect(analyser);

    const silenceThreshold = 0.02; // é™éŸ³é˜ˆå€¼
    const minRecordingTime = 5000; // æœ€å°å½•éŸ³ä¿æŠ¤æœŸï¼ˆ5ç§’ï¼‰
    const maxSilenceTime = 3000; // æœ€å¤§é™éŸ³æ—¶é•¿ï¼ˆ3ç§’ï¼‰
    const maxRecordingTime = 60000; // æœ€å¤§å½•éŸ³æ—¶é•¿ï¼ˆ60ç§’ï¼‰

    let silenceStartTime: number | null = null;
    let totalAudioEnergy = 0; // è®°å½•æ€»éŸ³é¢‘èƒ½é‡ç”¨äºå…¨ç¨‹é™éŸ³æ£€æµ‹
    let samplesCount = 0;

    // å®æ—¶æ£€æµ‹ï¼ˆæ¯ 100ms æ£€æµ‹ä¸€æ¬¡ï¼‰
    const checkInterval = setInterval(() => {
      const currentTime = Date.now();
      const recordingDuration = currentTime - startTimeRef.current;
      const level = analyzeAudioLevel(analyser);

      // ç´¯åŠ éŸ³é¢‘èƒ½é‡ç”¨äºå…¨ç¨‹é™éŸ³æ£€æµ‹
      totalAudioEnergy += level;
      samplesCount++;

      const isSilence = level < silenceThreshold;

      // æœ€å¤§å½•éŸ³æ—¶é•¿æ£€æŸ¥
      if (recordingDuration >= maxRecordingTime) {
        console.log('ğŸ›‘ Max recording time reached (60s), stopping...');
        stopRecording();
        clearInterval(checkInterval);
        return;
      }

      // æœ€å°å½•éŸ³ä¿æŠ¤æœŸï¼š5ç§’å†…å¼ºåˆ¶å½•éŸ³ï¼Œä¸åœæ­¢
      if (recordingDuration < minRecordingTime) {
        // ä¿æŠ¤æœŸå†…å¿½ç•¥æˆªæ–­é€»è¾‘ï¼Œé‡ç½®é™éŸ³è®¡æ—¶
        silenceStartTime = null;
        return;
      }

      // 5ç§’åï¼šæ£€æµ‹é™éŸ³æ—¶é•¿
      if (isSilence) {
        if (!silenceStartTime) {
          silenceStartTime = currentTime;
          console.log('â¸ï¸ Silence detected, starting silence timer...');
        }

        const silenceDuration = currentTime - silenceStartTime;
        if (silenceDuration >= maxSilenceTime) {
          console.log(`ğŸ›‘ Silence for ${silenceDuration}ms, stopping recording...`);
          stopRecording();
          clearInterval(checkInterval);
        }
      } else {
        // æ£€æµ‹åˆ°è¯­éŸ³ï¼Œé‡ç½®é™éŸ³è®¡æ—¶
        if (silenceStartTime) {
          console.log('ğŸ—£ï¸ Voice detected, resetting silence timer');
        }
        silenceStartTime = null;
      }

      // å®æ—¶éŸ³é¢‘çº§åˆ«æ—¥å¿—ï¼ˆæ¯ç§’ä¸€æ¬¡ï¼‰
      if (samplesCount % 10 === 0) {
        console.log(`ğŸ¤ Audio level: ${level.toFixed(4)} | Duration: ${(recordingDuration / 1000).toFixed(1)}s | Silence: ${silenceStartTime ? ((currentTime - silenceStartTime) / 1000).toFixed(1) + 's' : '0s'}`);
      }
    }, 100);

    // è¿”å›æ¸…ç†å‡½æ•°ï¼ŒåŒ…å«æ€»èƒ½é‡ä¿¡æ¯
    return () => {
      clearInterval(checkInterval);
      analyser.disconnect();
      source.disconnect();
      audioContext.close();

      // è®¡ç®—å¹³å‡éŸ³é¢‘èƒ½é‡
      const avgAudioEnergy = samplesCount > 0 ? totalAudioEnergy / samplesCount : 0;
      return { avgAudioEnergy, samplesCount };
    };
  }, [analyzeAudioLevel, stopRecording]);

  const startRecording = useCallback(async () => {
    setError(null);
    setAudioBlob(null);
    setAudioDuration(0);
    setIsRecordingReady(false);
    setIsTooShort(false);

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      setIsRecordingReady(true);
      console.log('ğŸ¤ Microphone stream acquired, recorder ready');

      // é€‰æ‹©åˆé€‚çš„ MIME ç±»å‹ï¼ˆä¼˜å…ˆ webm/opusï¼Œå›é€€åˆ°æµè§ˆå™¨é»˜è®¤ï¼‰
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : MediaRecorder.isTypeSupported('audio/webm')
          ? 'audio/webm'
          : undefined; // ä½¿ç”¨æµè§ˆå™¨é»˜è®¤

      const mediaRecorder = new MediaRecorder(stream, {
        ...(mimeType && { mimeType }),
        // 128 kbps æ˜¯è¯­éŸ³å½•éŸ³çš„åˆç†æ¯”ç‰¹ç‡
        audioBitsPerSecond: 128000,
      });

      console.log(`ğŸ™ï¸ MediaRecorder created with mimeType: ${mediaRecorder.mimeType}`);

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          audioChunksRef.current!.push(event.data);
          console.log(`ğŸ“¦ Audio chunk received: ${event.data.size} bytes`);
        }
      };

      mediaRecorder.onstop = () => {
        const duration = (Date.now() - startTimeRef.current) / 1000;
        console.log(`ğŸ“¼ Recording completed: ${duration.toFixed(2)}s`);

        // æ£€æŸ¥æ˜¯å¦è¿‡çŸ­ï¼ˆ< 1ç§’ï¼‰
        if (duration < 1.0) {
          console.warn('âš ï¸ Recording too short (< 1.0s), discarding...');
          setIsTooShort(true);
          setAudioBlob(null);
          setAudioDuration(0);
          return;
        }

        const audioBlob = new Blob(audioChunksRef.current!, { type: mediaRecorder.mimeType || 'audio/webm' });
        console.log(`ğŸ“€ Audio blob created: ${audioBlob.size} bytes, type: ${audioBlob.type}`);
        
        // æ£€æŸ¥éŸ³é¢‘å¤§å°æ˜¯å¦åˆç†ï¼ˆè‡³å°‘ 5KBï¼Œå¦åˆ™å¯èƒ½æ˜¯ç©ºéŸ³é¢‘ï¼‰
        if (audioBlob.size < 5000) {
          console.warn(`âš ï¸ Audio blob too small (${audioBlob.size} bytes), might be empty`);
          setIsTooShort(true);
          setAudioBlob(null);
          setAudioDuration(0);
          return;
        }
        
        setAudioBlob(audioBlob);
        setAudioDuration(duration);
      };

      // ä½¿ç”¨ timeslice å‚æ•°ï¼Œæ¯ 500ms æ”¶é›†ä¸€æ¬¡æ•°æ®ï¼Œç¡®ä¿å¢é‡æ•è·
      mediaRecorder.start(500);
      startTimeRef.current = Date.now();
      setIsRecording(true);
      console.log('Recording started (5s protection period)');

      // å¯åŠ¨é™éŸ³æ£€æµ‹
      const cleanupDetection = checkSilence();

      // å½•éŸ³ç»“æŸååœæ­¢æ£€æµ‹å¹¶å¤„ç†
      const originalOnStop = mediaRecorder.onstop;
      mediaRecorder.onstop = (event) => {
        const energyInfo: EnergyInfo = cleanupDetection ? cleanupDetection() as EnergyInfo : { avgAudioEnergy: 0, samplesCount: 0 };

        console.log(`ğŸ“Š Audio analysis: avgEnergy=${energyInfo.avgAudioEnergy.toFixed(4)}, samples=${energyInfo.samplesCount}`);

        // æ£€æŸ¥æ˜¯å¦å…¨ç¨‹é™éŸ³ï¼ˆå¹³å‡èƒ½é‡ < é˜ˆå€¼ï¼‰
        if (energyInfo.avgAudioEnergy < 0.01 && energyInfo.samplesCount > 10) {
          console.warn('âš ï¸ Full silence detected, discarding recording...');
          setIsTooShort(true);
          setAudioBlob(null);
          setAudioDuration(0);
        }

        // è°ƒç”¨åŸå§‹çš„ onstop å¤„ç†
        if (originalOnStop) {
          originalOnStop.call(mediaRecorder, event);
        }

        mediaRecorder.onstop = null;
      };

    } catch (err: unknown) {
      console.error('Failed to start recording:', err);
      const errorMessage = err instanceof Error ? err.message : 'Unknown error';
      setError('æ— æ³•è®¿é—®éº¦å…‹é£: ' + errorMessage);
    }
  }, [checkSilence]);

  return {
    isRecording,
    isRecordingReady,
    startRecording,
    stopRecording,
    audioBlob,
    audioDuration,
    error,
    isTooShort,
  };
}