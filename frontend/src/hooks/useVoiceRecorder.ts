import { useState, useRef, useCallback } from 'react';

/**
 * Voice Recorder Hook
 *
 * ä½¿ç”¨ MediaRecorder API è¿›è¡Œå½•éŸ³ï¼Œæ”¯æŒæ™ºèƒ½é™éŸ³æ£€æµ‹ï¼ˆVADï¼‰
 *
 * æ ¸å¿ƒç®—æ³•ï¼ˆå”¤é†’åè¯­éŸ³è¾“å…¥ï¼‰ï¼š
 * 1. åˆå§‹è¶…æ—¶ï¼šå”¤é†’åæœ‰ 3 ç§’çª—å£æœŸç­‰å¾…è¯­éŸ³è¾“å…¥
 * 2. åŠ¨æ€å»¶é•¿ï¼šæ¯æ¬¡æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå»¶é•¿ 1 ç§’è¶…æ—¶
 * 3. è‡ªåŠ¨ç»“æŸï¼šè¶…æ—¶æ— è¯­éŸ³è¾“å…¥åˆ™è‡ªåŠ¨åœæ­¢
 * 4. æœ€å¤§å½•éŸ³æ—¶é•¿ï¼š60ç§’è‡ªåŠ¨åœæ­¢
 * 5. å…¨ç¨‹é™éŸ³æ£€æµ‹ï¼šä½èƒ½é‡éŸ³é¢‘è‡ªåŠ¨ä¸¢å¼ƒ
 */
export interface UseVoiceRecorderReturn {
  isRecording: boolean;
  isRecordingReady: boolean; // å½•éŸ³æœºæ˜¯å¦å·²å‡†å¤‡å¥½ï¼ˆè·å–åˆ°éº¦å…‹é£æµåï¼‰
  startRecording: () => void;
  stopRecording: () => void;
  audioBlob: Blob | null;
  audioDuration: number;
  error: string | null;
  isTooShort: boolean; // å½•éŸ³æ—¶é•¿æ˜¯å¦è¿‡çŸ­ï¼ˆ< 0.5ç§’ï¼‰
}

interface EnergyInfo {
  avgAudioEnergy: number;
  samplesCount: number;
}

type CleanupFunction = () => EnergyInfo | void;

export function useVoiceRecorder(): UseVoiceRecorderReturn {
  const [isRecording, setIsRecording] = useState(false);
  const [isRecordingReady, setIsRecordingReady] = useState(false);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [audioDuration, setAudioDuration] = useState(0);
  const [error, setError] = useState<string | null>(null);
  const [isTooShort, setIsTooShort] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const startTimeRef = useRef<number>(0);

  // é™éŸ³æ£€æµ‹
  const analyzeAudioLevel = useCallback((analyser: AnalyserNode) => {
    if (!mediaRecorderRef.current) return 0;

    const dataArray = new Float32Array(analyser.fftSize);
    analyser.getFloatFrequencyData(dataArray);

    // è®¡ç®—éŸ³é¢‘èƒ½é‡ï¼ˆRMSï¼‰
    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) {
      sum += dataArray[i] * dataArray[i];
    }
    const rms = Math.sqrt(sum / dataArray.length);
    return rms;
  }, []);

  // é‡Šæ”¾éº¦å…‹é£æµ
  const releaseStream = useCallback(() => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log('ğŸ”‡ Audio track stopped');
      });
      streamRef.current = null;
    }
  }, []);

  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      const duration = (Date.now() - startTimeRef.current) / 1000;
      
      // å¼ºåˆ¶æœ€å°‘å½•éŸ³ 0.5 ç§’
      if (duration < 0.5) {
        console.log(`â³ Recording too short (${duration.toFixed(2)}s), waiting for minimum 0.5s...`);
        // å»¶è¿Ÿåœæ­¢ï¼Œç¡®ä¿è‡³å°‘ 0.5 ç§’
        const remainingTime = (0.5 - duration) * 1000;
        setTimeout(() => {
          if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
            mediaRecorderRef.current.stop();
            setIsRecording(false);
            releaseStream();
            console.log('Recording stopped (after minimum time)');
          }
        }, remainingTime);
        return;
      }
      
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      releaseStream();
      console.log(`ğŸ›‘ Recording stopped (${duration.toFixed(2)}s)`);
    }
  }, [releaseStream]);

  const checkSilence = useCallback((): CleanupFunction => {
    if (!mediaRecorderRef.current) return () => ({ avgAudioEnergy: 0, samplesCount: 0 });

    const audioContext = new (window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext)();
    const source = audioContext.createMediaStreamSource(
      mediaRecorderRef.current.stream || new MediaStream()
    );
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = 256;
    source.connect(analyser);

    const silenceThreshold = 0.02; // é™éŸ³é˜ˆå€¼
    const initialTimeout = 3000; // åˆå§‹è¶…æ—¶æ—¶é—´ï¼ˆ3ç§’ï¼‰
    const extensionTime = 1000; // æ¯æ¬¡è¯­éŸ³è¾“å…¥å»¶é•¿æ—¶é—´ï¼ˆ1ç§’ï¼‰
    const maxRecordingTime = 60000; // æœ€å¤§å½•éŸ³æ—¶é•¿ï¼ˆ60ç§’ï¼‰
    const minRecordingTime = 500; // æœ€å°å½•éŸ³æ—¶é•¿ï¼ˆ0.5ç§’ï¼Œç¡®ä¿æœ‰æ•ˆå½•éŸ³ï¼‰

    let timeoutDeadline = startTimeRef.current + initialTimeout; // è¶…æ—¶æˆªæ­¢æ—¶é—´
    let totalAudioEnergy = 0; // è®°å½•æ€»éŸ³é¢‘èƒ½é‡ç”¨äºå…¨ç¨‹é™éŸ³æ£€æµ‹
    let samplesCount = 0;
    let hasVoiceInput = false; // æ˜¯å¦æ£€æµ‹åˆ°è¿‡è¯­éŸ³è¾“å…¥
    let lastVoiceTime = 0; // ä¸Šæ¬¡æ£€æµ‹åˆ°è¯­éŸ³çš„æ—¶é—´ï¼ˆç”¨äºé˜²æ­¢é¢‘ç¹å»¶é•¿ï¼‰

    console.log(`â±ï¸ Voice timeout initialized: ${initialTimeout}ms, deadline: ${new Date(timeoutDeadline).toLocaleTimeString()}`);

    // å®æ—¶æ£€æµ‹ï¼ˆæ¯ 100ms æ£€æµ‹ä¸€æ¬¡ï¼‰
    const checkInterval = setInterval(() => {
      const currentTime = Date.now();
      const recordingDuration = currentTime - startTimeRef.current;
      const level = analyzeAudioLevel(analyser);

      // ç´¯åŠ éŸ³é¢‘èƒ½é‡ç”¨äºå…¨ç¨‹é™éŸ³æ£€æµ‹
      totalAudioEnergy += level;
      samplesCount++;

      const isSilence = level < silenceThreshold;

      // æœ€å¤§å½•éŸ³æ—¶é•¿æ£€æŸ¥
      if (recordingDuration >= maxRecordingTime) {
        console.log('ğŸ›‘ Max recording time reached (60s), stopping...');
        stopRecording();
        clearInterval(checkInterval);
        return;
      }

      // æ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥
      if (!isSilence) {
        hasVoiceInput = true;
        
        // æ¯æ¬¡æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå»¶é•¿è¶…æ—¶æ—¶é—´ï¼ˆé˜²æŠ–ï¼šè‡³å°‘é—´éš” 500ms æ‰å»¶é•¿ï¼‰
        if (currentTime - lastVoiceTime > 500) {
          const newDeadline = currentTime + extensionTime;
          // åªæœ‰å½“æ–°çš„æˆªæ­¢æ—¶é—´æ›´æ™šæ—¶æ‰å»¶é•¿
          if (newDeadline > timeoutDeadline) {
            timeoutDeadline = newDeadline;
            console.log(`ğŸ—£ï¸ Voice detected! Extending timeout by ${extensionTime}ms, new deadline: +${((timeoutDeadline - startTimeRef.current) / 1000).toFixed(1)}s`);
          }
          lastVoiceTime = currentTime;
        }
      }

      // æ£€æŸ¥æ˜¯å¦è¶…æ—¶
      const remainingTime = timeoutDeadline - currentTime;
      if (remainingTime <= 0 && recordingDuration >= minRecordingTime) {
        if (hasVoiceInput) {
          console.log(`ğŸ›‘ Timeout reached after voice input, stopping recording... (duration: ${(recordingDuration / 1000).toFixed(1)}s)`);
        } else {
          console.log(`ğŸ›‘ No voice input within ${initialTimeout}ms, stopping recording...`);
        }
        stopRecording();
        clearInterval(checkInterval);
        return;
      }

      // å®æ—¶éŸ³é¢‘çº§åˆ«æ—¥å¿—ï¼ˆæ¯ç§’ä¸€æ¬¡ï¼‰
      if (samplesCount % 10 === 0) {
        console.log(`ğŸ¤ Audio level: ${level.toFixed(4)} | Duration: ${(recordingDuration / 1000).toFixed(1)}s | Timeout in: ${(remainingTime / 1000).toFixed(1)}s`);
      }
    }, 100);

    // è¿”å›æ¸…ç†å‡½æ•°ï¼ŒåŒ…å«æ€»èƒ½é‡ä¿¡æ¯
    return () => {
      clearInterval(checkInterval);
      analyser.disconnect();
      source.disconnect();
      audioContext.close();

      // è®¡ç®—å¹³å‡éŸ³é¢‘èƒ½é‡
      const avgAudioEnergy = samplesCount > 0 ? totalAudioEnergy / samplesCount : 0;
      return { avgAudioEnergy, samplesCount };
    };
  }, [analyzeAudioLevel, stopRecording]);

  const startRecording = useCallback(async () => {
    setError(null);
    setAudioBlob(null);
    setAudioDuration(0);
    setIsRecordingReady(false);
    setIsTooShort(false);

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      setIsRecordingReady(true);
      console.log('ğŸ¤ Microphone stream acquired, recorder ready');

      // é€‰æ‹©åˆé€‚çš„ MIME ç±»å‹ï¼ˆä¼˜å…ˆ webm/opusï¼Œå›é€€åˆ°æµè§ˆå™¨é»˜è®¤ï¼‰
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : MediaRecorder.isTypeSupported('audio/webm')
          ? 'audio/webm'
          : undefined; // ä½¿ç”¨æµè§ˆå™¨é»˜è®¤

      const mediaRecorder = new MediaRecorder(stream, {
        ...(mimeType && { mimeType }),
        // 128 kbps æ˜¯è¯­éŸ³å½•éŸ³çš„åˆç†æ¯”ç‰¹ç‡
        audioBitsPerSecond: 128000,
      });

      console.log(`ğŸ™ï¸ MediaRecorder created with mimeType: ${mediaRecorder.mimeType}`);

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          audioChunksRef.current!.push(event.data);
          console.log(`ğŸ“¦ Audio chunk received: ${event.data.size} bytes`);
        }
      };

      mediaRecorder.onstop = () => {
        const duration = (Date.now() - startTimeRef.current) / 1000;
        console.log(`ğŸ“¼ Recording completed: ${duration.toFixed(2)}s`);

        // æ£€æŸ¥æ˜¯å¦è¿‡çŸ­ï¼ˆ< 0.5ç§’ï¼‰
        if (duration < 0.5) {
          console.warn('âš ï¸ Recording too short (< 0.5s), discarding...');
          setIsTooShort(true);
          setAudioBlob(null);
          setAudioDuration(0);
          return;
        }

        const audioBlob = new Blob(audioChunksRef.current!, { type: mediaRecorder.mimeType || 'audio/webm' });
        console.log(`ğŸ“€ Audio blob created: ${audioBlob.size} bytes, type: ${audioBlob.type}`);
        
        // æ£€æŸ¥éŸ³é¢‘å¤§å°æ˜¯å¦åˆç†ï¼ˆè‡³å°‘ 5KBï¼Œå¦åˆ™å¯èƒ½æ˜¯ç©ºéŸ³é¢‘ï¼‰
        if (audioBlob.size < 5000) {
          console.warn(`âš ï¸ Audio blob too small (${audioBlob.size} bytes), might be empty`);
          setIsTooShort(true);
          setAudioBlob(null);
          setAudioDuration(0);
          return;
        }
        
        setAudioBlob(audioBlob);
        setAudioDuration(duration);
      };

      // ä½¿ç”¨ timeslice å‚æ•°ï¼Œæ¯ 500ms æ”¶é›†ä¸€æ¬¡æ•°æ®ï¼Œç¡®ä¿å¢é‡æ•è·
      mediaRecorder.start(500);
      startTimeRef.current = Date.now();
      setIsRecording(true);
      console.log('ğŸ¤ Recording started (3s initial timeout, +1s per voice input)');

      // å¯åŠ¨é™éŸ³æ£€æµ‹
      const cleanupDetection = checkSilence();

      // å½•éŸ³ç»“æŸååœæ­¢æ£€æµ‹å¹¶å¤„ç†
      const originalOnStop = mediaRecorder.onstop;
      mediaRecorder.onstop = (event) => {
        const energyInfo: EnergyInfo = cleanupDetection ? cleanupDetection() as EnergyInfo : { avgAudioEnergy: 0, samplesCount: 0 };

        console.log(`ğŸ“Š Audio analysis: avgEnergy=${energyInfo.avgAudioEnergy.toFixed(4)}, samples=${energyInfo.samplesCount}`);

        // æ£€æŸ¥æ˜¯å¦å…¨ç¨‹é™éŸ³ï¼ˆå¹³å‡èƒ½é‡ < é˜ˆå€¼ï¼‰
        if (energyInfo.avgAudioEnergy < 0.01 && energyInfo.samplesCount > 10) {
          console.warn('âš ï¸ Full silence detected, discarding recording...');
          setIsTooShort(true);
          setAudioBlob(null);
          setAudioDuration(0);
        }

        // è°ƒç”¨åŸå§‹çš„ onstop å¤„ç†
        if (originalOnStop) {
          originalOnStop.call(mediaRecorder, event);
        }

        mediaRecorder.onstop = null;
      };

    } catch (err: unknown) {
      console.error('Failed to start recording:', err);
      const errorMessage = err instanceof Error ? err.message : 'Unknown error';
      setError('æ— æ³•è®¿é—®éº¦å…‹é£: ' + errorMessage);
    }
  }, [checkSilence]);

  return {
    isRecording,
    isRecordingReady,
    startRecording,
    stopRecording,
    audioBlob,
    audioDuration,
    error,
    isTooShort,
  };
}