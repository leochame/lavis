package com.lavis.service.llm.tts;

import com.alibaba.dashscope.aigc.multimodalconversation.AudioParameters;
import com.alibaba.dashscope.aigc.multimodalconversation.MultiModalConversation;
import com.alibaba.dashscope.aigc.multimodalconversation.MultiModalConversationParam;
import com.alibaba.dashscope.aigc.multimodalconversation.MultiModalConversationResult;
import com.alibaba.dashscope.exception.ApiException;
import com.alibaba.dashscope.exception.NoApiKeyException;
import com.alibaba.dashscope.exception.UploadFileException;
import com.alibaba.dashscope.utils.Constants;
import com.lavis.config.llm.ModelConfig;
import io.reactivex.Flowable;
import lombok.extern.slf4j.Slf4j;

import javax.sound.sampled.AudioFormat;
import javax.sound.sampled.AudioInputStream;
import javax.sound.sampled.AudioSystem;
import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.util.Base64;

/**
 * é˜¿é‡Œäº‘ DashScope åŸç”Ÿ TTS å®ç° (ä½¿ç”¨ SDK)
 * 
 * åŸºäº qwen3-tts-flash æ¨¡å‹ï¼Œä½¿ç”¨ MultiModalConversation API
 * æ–‡æ¡£: https://bailian.console.aliyun.com
 * 
 * æ”¯æŒçš„éŸ³è‰² (Voice):
 * - Cherry: å¥³å£°ï¼Œè‡ªç„¶æµç•…
 * - Dylan: ç”·å£°
 * - Jada: å¥³å£°
 * - Sunny: ç”·å£°
 */
@Slf4j
public class DashScopeTtsModel implements TtsModel {

    private final ModelConfig config;
    
    // DashScope API åŸºç¡€ URL (åŒ—äº¬åœ°åŸŸ)
    private static final String DASHSCOPE_BASE_URL = "https://dashscope.aliyuncs.com/api/v1";
    
    // éŸ³é¢‘æ ¼å¼å‚æ•° (SDK è¿”å› PCM æ ¼å¼)
    private static final float SAMPLE_RATE = 24000f;
    private static final int SAMPLE_SIZE_BITS = 16;
    private static final int CHANNELS = 1;
    private static final int FRAME_SIZE = 2;
    private static final boolean BIG_ENDIAN = false;

    public DashScopeTtsModel(ModelConfig config) {
        this.config = config;
        // è®¾ç½® DashScope API åŸºç¡€ URL
        Constants.baseHttpApiUrl = DASHSCOPE_BASE_URL;
    }

    @Override
    public String textToSpeech(String text) {
        if (text == null || text.trim().isEmpty()) {
            throw new IllegalArgumentException("Text is required");
        }

        try {
            log.info("ğŸ™ï¸ Starting DashScope TTS (SDK) for text ({} chars), model: {}, voice: {}", 
                text.length(), config.getModelName(), config.getVoice());

            // æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ•°æ®
            ByteArrayOutputStream audioBuffer = new ByteArrayOutputStream();
            
            // è°ƒç”¨æµå¼ TTS API
            streamCall(text, audioBuffer);
            
            byte[] pcmData = audioBuffer.toByteArray();
            
            if (pcmData.length == 0) {
                throw new RuntimeException("No audio data received from TTS API");
            }
            
            log.info("âœ… TTS audio generated successfully, PCM size: {} bytes", pcmData.length);
            
            // æ ¹æ®é…ç½®çš„è¾“å‡ºæ ¼å¼å¤„ç†éŸ³é¢‘
            String format = config.getFormat() != null ? config.getFormat().toLowerCase() : "mp3";
            byte[] outputData;
            
            if ("pcm".equals(format) || "raw".equals(format)) {
                // ç›´æ¥è¿”å› PCM æ•°æ®
                outputData = pcmData;
            } else if ("wav".equals(format)) {
                // è½¬æ¢ä¸º WAV æ ¼å¼
                outputData = pcmToWav(pcmData);
            } else {
                // é»˜è®¤è¿”å› PCM (å‰ç«¯å¯ä»¥ç›´æ¥æ’­æ”¾ PCM)
                // æ³¨æ„: å¦‚æœéœ€è¦ MP3 æ ¼å¼ï¼Œéœ€è¦é¢å¤–çš„ç¼–ç åº“
                outputData = pcmData;
                log.warn("âš ï¸ MP3 encoding not supported in SDK mode, returning PCM data");
            }
            
            return Base64.getEncoder().encodeToString(outputData);

        } catch (Exception e) {
            log.error("âŒ TTS generation failed", e);
            throw new RuntimeException("Failed to generate speech: " + e.getMessage(), e);
        }
    }

    /**
     * ä½¿ç”¨ DashScope SDK è¿›è¡Œæµå¼ TTS è°ƒç”¨
     */
    private void streamCall(String text, ByteArrayOutputStream audioBuffer) 
            throws ApiException, NoApiKeyException, UploadFileException {
        
        MultiModalConversation conv = new MultiModalConversation();
        
        // è§£æéŸ³è‰²é…ç½®
        AudioParameters.Voice voice = parseVoice(config.getVoice());
        
        // æ£€æµ‹è¯­è¨€ç±»å‹ (ç®€å•æ£€æµ‹)
        String languageType = detectLanguage(text);
        
        MultiModalConversationParam param = MultiModalConversationParam.builder()
                .apiKey(config.getApiKey())
                .model(config.getModelName())
                .text(text)
                .voice(voice)
                .languageType(languageType)
                .build();
        
        log.debug("TTS request: model={}, voice={}, language={}", 
            config.getModelName(), voice, languageType);
        
        Flowable<MultiModalConversationResult> result = conv.streamCall(param);
        
        result.blockingForEach(r -> {
            try {
                if (r.getOutput() != null && r.getOutput().getAudio() != null) {
                    String base64Data = r.getOutput().getAudio().getData();
                    if (base64Data != null && !base64Data.isEmpty()) {
                        byte[] audioBytes = Base64.getDecoder().decode(base64Data);
                        audioBuffer.write(audioBytes);
                    }
                }
            } catch (Exception e) {
                log.error("Error processing audio chunk", e);
            }
        });
    }

    /**
     * è§£æéŸ³è‰²é…ç½®å­—ç¬¦ä¸²ä¸º SDK æšä¸¾
     */
    private AudioParameters.Voice parseVoice(String voiceName) {
        if (voiceName == null || voiceName.isBlank()) {
            return AudioParameters.Voice.CHERRY; // é»˜è®¤éŸ³è‰²
        }
        
        return switch (voiceName.toLowerCase()) {
            case "cherry" -> AudioParameters.Voice.CHERRY;
            case "dylan" -> AudioParameters.Voice.DYLAN;
            case "jada" -> AudioParameters.Voice.JADA;
            case "sunny" -> AudioParameters.Voice.SUNNY;
            default -> {
                log.warn("Unknown voice '{}', using default Cherry", voiceName);
                yield AudioParameters.Voice.CHERRY;
            }
        };
    }

    /**
     * ç®€å•æ£€æµ‹æ–‡æœ¬è¯­è¨€
     * å»ºè®®ä¸æ–‡æœ¬è¯­ç§ä¸€è‡´ï¼Œä»¥è·å¾—æ­£ç¡®çš„å‘éŸ³å’Œè‡ªç„¶çš„è¯­è°ƒ
     */
    private String detectLanguage(String text) {
        if (text == null || text.isEmpty()) {
            return "Chinese";
        }
        
        // ç®€å•æ£€æµ‹ï¼šå¦‚æœåŒ…å«ä¸­æ–‡å­—ç¬¦åˆ™è®¤ä¸ºæ˜¯ä¸­æ–‡
        for (char c : text.toCharArray()) {
            if (Character.UnicodeScript.of(c) == Character.UnicodeScript.HAN) {
                return "Chinese";
            }
        }
        
        return "English";
    }

    /**
     * å°† PCM æ•°æ®è½¬æ¢ä¸º WAV æ ¼å¼
     */
    private byte[] pcmToWav(byte[] pcmData) {
        try {
            AudioFormat format = new AudioFormat(
                    AudioFormat.Encoding.PCM_SIGNED,
                    SAMPLE_RATE,
                    SAMPLE_SIZE_BITS,
                    CHANNELS,
                    FRAME_SIZE,
                    SAMPLE_RATE,
                    BIG_ENDIAN
            );
            
            ByteArrayInputStream bais = new ByteArrayInputStream(pcmData);
            AudioInputStream ais = new AudioInputStream(bais, format, pcmData.length / FRAME_SIZE);
            
            ByteArrayOutputStream baos = new ByteArrayOutputStream();
            AudioSystem.write(ais, javax.sound.sampled.AudioFileFormat.Type.WAVE, baos);
            
            return baos.toByteArray();
        } catch (Exception e) {
            log.error("Failed to convert PCM to WAV", e);
            // è¿”å›åŸå§‹ PCM æ•°æ®
            return pcmData;
        }
    }

    @Override
    public boolean isAvailable() {
        return config.getApiKey() != null && !config.getApiKey().isBlank();
    }
}
