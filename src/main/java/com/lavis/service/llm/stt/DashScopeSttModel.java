package com.lavis.service.llm.stt;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.node.ArrayNode;
import com.fasterxml.jackson.databind.node.ObjectNode;
import com.lavis.config.llm.ModelConfig;
import lombok.extern.slf4j.Slf4j;
import okhttp3.*;
import org.springframework.web.multipart.MultipartFile;

import java.io.IOException;
import java.util.Base64;
import java.util.concurrent.TimeUnit;

/**
 * é˜¿é‡Œäº‘ DashScope åŸç”Ÿ STT (è¯­éŸ³è¯†åˆ«) å®ç°
 * 
 * æ”¯æŒå¤šç§æ¨¡å‹å’Œ API:
 * 1. qwen3-asr-flash / qwen-audio-turbo -> å¤šæ¨¡æ€ç”Ÿæˆ API (åŒæ­¥ï¼Œæ”¯æŒ base64)
 * 2. sensevoice-v1 -> åŒæ­¥è¯†åˆ« API (recognition)
 * 3. qwen3-asr-flash-filetrans, fun-asr, paraformer -> å¼‚æ­¥è½¬å†™ API (transcription)
 * 
 * æ–‡æ¡£: https://help.aliyun.com/zh/model-studio/qwen-speech-recognition
 */
@Slf4j
public class DashScopeSttModel implements SttModel {

    private final ModelConfig config;
    private final OkHttpClient httpClient;
    private final ObjectMapper objectMapper = new ObjectMapper();

    // å¤šæ¨¡æ€ç”Ÿæˆ API (qwen3-asr-flash, qwen-audio ç³»åˆ—)
    private static final String MULTIMODAL_API_URL = "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation";
    // åŒæ­¥è¯­éŸ³è¯†åˆ« API (sensevoice, paraformer-realtime)
    private static final String SYNC_RECOGNITION_URL = "https://dashscope.aliyuncs.com/api/v1/services/audio/asr/recognition";
    // å¼‚æ­¥æ–‡ä»¶è½¬å†™ API (filetrans ç³»åˆ—)
    private static final String ASYNC_TRANSCRIPTION_URL = "https://dashscope.aliyuncs.com/api/v1/services/audio/asr/transcription";
    private static final MediaType JSON_MEDIA_TYPE = MediaType.parse("application/json; charset=utf-8");

    public DashScopeSttModel(ModelConfig config) {
        this.config = config;
        this.httpClient = new OkHttpClient.Builder()
                .connectTimeout(config.getTimeoutSeconds(), TimeUnit.SECONDS)
                .readTimeout(config.getTimeoutSeconds(), TimeUnit.SECONDS)
                .writeTimeout(config.getTimeoutSeconds(), TimeUnit.SECONDS)
                .build();
    }

    @Override
    public String transcribe(MultipartFile audioFile) {
        if (audioFile == null || audioFile.isEmpty()) {
            throw new IllegalArgumentException("Audio file is required");
        }

        try {
            String modelName = config.getModelName();
            log.info("ğŸ¤ Starting DashScope ASR for file: {}, model: {}",
                    audioFile.getOriginalFilename(), modelName);

            // æ ¹æ®æ¨¡å‹é€‰æ‹©æ­£ç¡®çš„ API å’Œè¯·æ±‚æ ¼å¼
            if (isQwenAudioModel(modelName)) {
                return transcribeWithMultimodalApi(audioFile, modelName);
            } else if (isAsyncModel(modelName)) {
                throw new UnsupportedOperationException(
                    "å¼‚æ­¥æ¨¡å‹ " + modelName + " éœ€è¦æ–‡ä»¶ URLï¼Œè¯·ä½¿ç”¨ sensevoice-v1 æˆ– qwen3-asr-flash");
            } else {
                return transcribeWithRecognitionApi(audioFile, modelName);
            }

        } catch (IOException e) {
            log.error("Transcription failed", e);
            throw new RuntimeException("Failed to transcribe audio: " + e.getMessage(), e);
        }
    }

    /**
     * ä½¿ç”¨å¤šæ¨¡æ€ç”Ÿæˆ API è¿›è¡Œè½¬å†™ (qwen3-asr-flash, qwen-audio-turbo ç­‰)
     * å‚è€ƒå®˜æ–¹æ–‡æ¡£: https://bailian.console.aliyun.com/cn-beijing/#/doc/?type=model&url=2979031
     * 
     * é‡è¦ï¼šqwen3-asr-flash æ˜¯ä¸“é—¨çš„ ASR æ¨¡å‹ï¼Œç”¨æˆ·æ¶ˆæ¯åªéœ€è¦åŒ…å«éŸ³é¢‘ï¼Œä¸éœ€è¦æ–‡å­—æç¤ºï¼
     */
    private String transcribeWithMultimodalApi(MultipartFile audioFile, String modelName) throws IOException {
        String apiUrl = config.getBaseUrl() != null && !config.getBaseUrl().isBlank()
                ? config.getBaseUrl() : MULTIMODAL_API_URL;

        log.info("ğŸ”— Using Multimodal Generation API: {}", apiUrl);
        log.info("ğŸ”‘ Using API Key prefix: {}...",
                config.getApiKey() != null && config.getApiKey().length() > 10
                        ? config.getApiKey().substring(0, 10) : "null");

        // 1. å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸º Base64 Data URI
        byte[] audioBytes = audioFile.getBytes();
        String audioBase64 = Base64.getEncoder().encodeToString(audioBytes);
        String mimeType = getAudioMimeType(audioFile.getOriginalFilename());
        String dataUri = "data:" + mimeType + ";base64," + audioBase64;
        
        log.info("ğŸ“ Audio MIME type: {}, size: {} bytes", mimeType, audioBytes.length);

        // 2. æ„å»ºå¤šæ¨¡æ€è¯·æ±‚ä½“ (æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼)
        // æ ¼å¼: {
        //   "model": "qwen3-asr-flash",
        //   "input": {
        //     "messages": [
        //       {"role": "system", "content": [{"text": ""}]},  // ç³»ç»Ÿæ¶ˆæ¯ï¼ˆç”¨äºå®šåˆ¶åŒ–è¯†åˆ«çš„Contextï¼‰
        //       {"role": "user", "content": [{"audio": "data:audio/mpeg;base64,..."}]}  // åªæœ‰éŸ³é¢‘ï¼Œæ— æ–‡å­—ï¼
        //     ]
        //   },
        //   "parameters": {
        //     "asr_options": {"enable_itn": false}
        //   }
        // }
        ObjectNode root = objectMapper.createObjectNode();
        root.put("model", modelName);

        ObjectNode input = root.putObject("input");
        ArrayNode messages = input.putArray("messages");
        
        // ç³»ç»Ÿæ¶ˆæ¯ï¼ˆç”¨äºå®šåˆ¶åŒ–è¯†åˆ«çš„ Contextï¼Œå¯ä¸ºç©ºï¼‰
        ObjectNode sysMessage = messages.addObject();
        sysMessage.put("role", "system");
        ArrayNode sysContent = sysMessage.putArray("content");
        ObjectNode sysText = sysContent.addObject();
        sysText.put("text", "");  // ç©ºæ–‡æœ¬ï¼Œç”¨äºå®šåˆ¶åŒ–è¯†åˆ«
        
        // ç”¨æˆ·æ¶ˆæ¯ - é‡è¦ï¼šåªåŒ…å«éŸ³é¢‘ï¼Œä¸éœ€è¦æ–‡å­—æç¤ºï¼
        ObjectNode userMessage = messages.addObject();
        userMessage.put("role", "user");
        ArrayNode userContent = userMessage.putArray("content");
        ObjectNode audioContent = userContent.addObject();
        audioContent.put("audio", dataUri);
        
        // ASR é€‰é¡¹å‚æ•°
        ObjectNode parameters = root.putObject("parameters");
        ObjectNode asrOptions = parameters.putObject("asr_options");
        asrOptions.put("enable_itn", true);  // å¯ç”¨é€†æ–‡æœ¬æ­£åˆ™åŒ–ï¼ˆæ•°å­—/æ—¥æœŸç­‰è½¬æ¢ï¼‰
        // asrOptions.put("language", "zh");  // å¯é€‰ï¼šæŒ‡å®šè¯­ç§ä»¥æå‡å‡†ç¡®ç‡

        String requestJson = root.toString();
        log.debug("ğŸ“¤ Request body length: {} chars", requestJson.length());

        RequestBody requestBody = RequestBody.create(requestJson, JSON_MEDIA_TYPE);

        Request request = new Request.Builder()
                .url(apiUrl)
                .addHeader("Authorization", "Bearer " + config.getApiKey())
                .addHeader("Content-Type", "application/json")
                .post(requestBody)
                .build();

        // 3. å‘é€è¯·æ±‚
        try (Response response = httpClient.newCall(request).execute()) {
            String responseBody = response.body() != null ? response.body().string() : "";

            if (!response.isSuccessful()) {
                log.error("âŒ DashScope Multimodal API failed: {} - URL: {}", response.code(), apiUrl);
                log.error("âŒ Error response body: {}", responseBody);
                throw new IOException("ASR transcription failed: " + response.code() + " - " + responseBody);
            }

            log.debug("ğŸ“ DashScope response: {}", responseBody);
            return parseMultimodalResult(responseBody);
        }
    }

    /**
     * ä½¿ç”¨åŒæ­¥è¯†åˆ« API (sensevoice-v1 ç­‰ä¼ ç»Ÿæ¨¡å‹)
     */
    private String transcribeWithRecognitionApi(MultipartFile audioFile, String modelName) throws IOException {
        String apiUrl = config.getBaseUrl() != null && !config.getBaseUrl().isBlank()
                ? config.getBaseUrl() : SYNC_RECOGNITION_URL;

        log.info("ğŸ”— Using Recognition API: {}", apiUrl);

        byte[] audioBytes = audioFile.getBytes();
        String audioBase64 = Base64.getEncoder().encodeToString(audioBytes);
        String format = getAudioFormat(audioFile.getOriginalFilename());
        
        log.info("ğŸ“ Audio format: {}, size: {} bytes", format, audioBytes.length);

        // æ„å»ºè¯†åˆ«è¯·æ±‚
        ObjectNode root = objectMapper.createObjectNode();
        root.put("model", modelName);

        ObjectNode input = root.putObject("input");
        input.put("audio", "data:audio/" + format + ";base64," + audioBase64);

        ObjectNode parameters = root.putObject("parameters");
        parameters.put("format", format);

        RequestBody requestBody = RequestBody.create(root.toString(), JSON_MEDIA_TYPE);

        Request request = new Request.Builder()
                .url(apiUrl)
                .addHeader("Authorization", "Bearer " + config.getApiKey())
                .addHeader("Content-Type", "application/json")
                .post(requestBody)
                .build();

        try (Response response = httpClient.newCall(request).execute()) {
            String responseBody = response.body() != null ? response.body().string() : "";

            if (!response.isSuccessful()) {
                log.error("âŒ DashScope Recognition API failed: {} - URL: {}", response.code(), apiUrl);
                log.error("âŒ Error response body: {}", responseBody);
                throw new IOException("ASR transcription failed: " + response.code() + " - " + responseBody);
            }

            return parseTranscriptionResult(responseBody);
        }
    }

    /**
     * åˆ¤æ–­æ˜¯å¦ä¸º Qwen Audio ç³»åˆ—æ¨¡å‹ (ä½¿ç”¨å¤šæ¨¡æ€ API)
     */
    private boolean isQwenAudioModel(String modelName) {
        return modelName.contains("qwen3-asr") 
                || modelName.contains("qwen-audio")
                || modelName.contains("qwen2-audio");
    }

    /**
     * åˆ¤æ–­æ˜¯å¦ä¸ºå¼‚æ­¥æ¨¡å‹
     */
    private boolean isAsyncModel(String modelName) {
        return modelName.contains("filetrans") 
                || modelName.contains("fun-asr") 
                || modelName.contains("paraformer-v2");
    }

    /**
     * è§£æå¤šæ¨¡æ€ API å“åº”
     * å“åº”æ ¼å¼ç¤ºä¾‹:
     * {
     *   "output": {
     *     "choices": [{
     *       "message": {
     *         "role": "assistant",
     *         "content": [{"text": "è½¬å½•çš„æ–‡æœ¬å†…å®¹"}]
     *       }
     *     }]
     *   },
     *   "usage": {...},
     *   "request_id": "..."
     * }
     */
    private String parseMultimodalResult(String responseBody) {
        try {
            JsonNode root = objectMapper.readTree(responseBody);

            // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if (root.has("code") && !root.get("code").asText().isEmpty()) {
                String errorCode = root.get("code").asText();
                String errorMessage = root.has("message") ? root.get("message").asText() : "Unknown error";
                throw new RuntimeException("DashScope error: " + errorCode + " - " + errorMessage);
            }

            // è§£æå¤šæ¨¡æ€å“åº”æ ¼å¼
            JsonNode output = root.get("output");
            if (output != null && output.has("choices")) {
                JsonNode choices = output.get("choices");
                if (choices.isArray() && choices.size() > 0) {
                    JsonNode firstChoice = choices.get(0);
                    JsonNode message = firstChoice.get("message");
                    if (message != null) {
                        // content å¯èƒ½æ˜¯æ•°ç»„æˆ–å­—ç¬¦ä¸²
                        JsonNode content = message.get("content");
                        if (content != null) {
                            if (content.isArray()) {
                                StringBuilder result = new StringBuilder();
                                for (JsonNode item : content) {
                                    if (item.has("text")) {
                                        result.append(item.get("text").asText());
                                    }
                                }
                                String text = result.toString().trim();
                                log.info("âœ… Transcription successful: {} chars", text.length());
                                return text;
                            } else if (content.isTextual()) {
                                String text = content.asText().trim();
                                log.info("âœ… Transcription successful: {} chars", text.length());
                                return text;
                            }
                        }
                    }
                }
            }

            log.warn("âš ï¸ Could not parse multimodal result, returning raw response");
            return responseBody;

        } catch (IOException e) {
            log.error("Failed to parse multimodal response", e);
            return responseBody;
        }
    }

    /**
     * è§£æä¼ ç»Ÿ ASR å“åº”ï¼Œæå–è¯†åˆ«æ–‡æœ¬
     * å“åº”æ ¼å¼ç¤ºä¾‹:
     * {
     *   "output": {
     *     "text": "è¯†åˆ«çš„æ–‡æœ¬å†…å®¹",
     *     "sentence": {...}
     *   },
     *   "usage": {...},
     *   "request_id": "..."
     * }
     */
    private String parseTranscriptionResult(String responseBody) {
        try {
            JsonNode root = objectMapper.readTree(responseBody);

            // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if (root.has("code") && !root.get("code").asText().isEmpty()) {
                String errorCode = root.get("code").asText();
                String errorMessage = root.has("message") ? root.get("message").asText() : "Unknown error";
                throw new RuntimeException("DashScope ASR error: " + errorCode + " - " + errorMessage);
            }

            // æå–è¾“å‡ºæ–‡æœ¬
            JsonNode output = root.get("output");
            if (output != null) {
                // å°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
                if (output.has("text")) {
                    String text = output.get("text").asText();
                    log.info("âœ… Transcription successful: {} chars", text.length());
                    return text;
                }
                if (output.has("sentence") && output.get("sentence").has("text")) {
                    String text = output.get("sentence").get("text").asText();
                    log.info("âœ… Transcription successful: {} chars", text.length());
                    return text;
                }
                // qwen3-asr-flash å¯èƒ½ç›´æ¥è¿”å› sentences æ•°ç»„
                if (output.has("sentences") && output.get("sentences").isArray()) {
                    StringBuilder fullText = new StringBuilder();
                    for (JsonNode sentence : output.get("sentences")) {
                        if (sentence.has("text")) {
                            fullText.append(sentence.get("text").asText());
                        }
                    }
                    String text = fullText.toString();
                    log.info("âœ… Transcription successful: {} chars", text.length());
                    return text;
                }
            }

            // å¦‚æœæ— æ³•è§£æï¼Œè¿”å›åŸå§‹å“åº”
            log.warn("âš ï¸ Could not parse transcription result, returning raw response");
            return responseBody;

        } catch (IOException e) {
            log.error("Failed to parse ASR response", e);
            return responseBody;
        }
    }

    /**
     * æ ¹æ®æ–‡ä»¶åè·å–éŸ³é¢‘ MIME ç±»å‹
     * å‚è€ƒå®˜æ–¹ç¤ºä¾‹: "data:" + AUDIO_MIME_TYPE + ";base64," + encoded
     */
    private String getAudioMimeType(String filename) {
        if (filename == null) {
            return "audio/webm"; // é»˜è®¤æ ¼å¼
        }
        String lowerName = filename.toLowerCase();
        if (lowerName.endsWith(".webm")) return "audio/webm";
        if (lowerName.endsWith(".wav")) return "audio/wav";
        if (lowerName.endsWith(".mp3")) return "audio/mpeg";
        if (lowerName.endsWith(".m4a")) return "audio/mp4";
        if (lowerName.endsWith(".ogg")) return "audio/ogg";
        if (lowerName.endsWith(".flac")) return "audio/flac";
        if (lowerName.endsWith(".aac")) return "audio/aac";
        if (lowerName.endsWith(".opus")) return "audio/opus";
        if (lowerName.endsWith(".pcm")) return "audio/pcm";
        // é»˜è®¤è¿”å› webmï¼ˆæµè§ˆå™¨å½•éŸ³å¸¸ç”¨æ ¼å¼ï¼‰
        return "audio/webm";
    }

    /**
     * æ ¹æ®æ–‡ä»¶åè·å–éŸ³é¢‘æ ¼å¼ï¼ˆçŸ­æ ¼å¼ï¼Œç”¨äº parameters.formatï¼‰
     */
    private String getAudioFormat(String filename) {
        if (filename == null) {
            return "webm";
        }
        String lowerName = filename.toLowerCase();
        if (lowerName.endsWith(".webm")) return "webm";
        if (lowerName.endsWith(".wav")) return "wav";
        if (lowerName.endsWith(".mp3")) return "mp3";
        if (lowerName.endsWith(".m4a")) return "m4a";
        if (lowerName.endsWith(".ogg")) return "ogg";
        if (lowerName.endsWith(".flac")) return "flac";
        if (lowerName.endsWith(".aac")) return "aac";
        if (lowerName.endsWith(".opus")) return "opus";
        if (lowerName.endsWith(".pcm")) return "pcm";
        return "webm";
    }

    @Override
    public boolean isAvailable() {
        return config.getApiKey() != null && !config.getApiKey().isBlank();
    }
}

